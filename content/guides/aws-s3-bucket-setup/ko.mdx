---
title: "AWS S3 버킷 생성 및 설정하기"
description: "AWS S3 버킷을 만들고 파일 업로드, 권한 관리, 정적 웹사이트 호스팅을 설정하는 방법을 배워보세요"
---

# AWS S3 버킷 생성 및 설정하기

AWS S3(Simple Storage Service)는 확장 가능한 객체 스토리지 서비스로, 파일 저장, 백업, 정적 웹사이트 호스팅 등 다양한 용도로 사용됩니다. 이 가이드에서는 S3 버킷을 생성하고 기본적인 설정 방법을 단계별로 안내합니다.

<FreeTierInfo />

<Callout type="info" title="S3의 주요 특징">
- **내구성**: 99.999999999%(11개의 9) 데이터 내구성
- **확장성**: 무제한 저장 공간
- **다양한 스토리지 클래스**: Standard, IA, Glacier 등 비용 최적화 옵션
- **보안**: 암호화, 액세스 제어, 버전 관리 지원
</Callout>

<PrerequisiteCheck prerequisites={["aws-account-setup", "aws-iam-user-create"]} />

---

<Step number={1} title="S3 서비스로 이동">

AWS Management Console에서 S3 서비스로 이동합니다.

1. AWS Management Console 상단의 검색창에 **"S3"** 입력
2. 검색 결과에서 **S3** 클릭

<Screenshot
  src="https://res.cloudinary.com/demo/image/upload/v1/guides/aws-s3-bucket-setup/step1-s3-console-ko.png"
  alt="AWS Console에서 S3 검색"
  caption="검색창에서 S3를 찾아 클릭합니다"
/>

<Checkpoint>
S3 대시보드에 접속했나요? "버킷" 목록과 "버킷 만들기" 버튼이 보여야 합니다.
</Checkpoint>

</Step>

---

<Step number={2} title="새 S3 버킷 생성">

첫 번째 S3 버킷을 생성합니다.

1. **"버킷 만들기"** 버튼 클릭
2. **버킷 이름** 입력 (전 세계적으로 고유해야 함)
   - 예: `my-app-storage-2026` (소문자, 숫자, 하이픈만 사용)
   - DNS 호환 이름이어야 함 (3-63자)
3. **AWS 리전** 선택
   - 한국 사용자는 **"아시아 태평양(서울) ap-northeast-2"** 권장
4. 나머지 설정은 기본값 유지
5. 페이지 하단의 **"버킷 만들기"** 클릭

<Screenshot
  src="https://res.cloudinary.com/demo/image/upload/v1/guides/aws-s3-bucket-setup/step2-create-bucket-ko.png"
  alt="S3 버킷 생성 화면"
  caption="버킷 이름과 리전을 설정합니다"
/>

<Callout type="warning" title="버킷 이름 규칙">
- 버킷 이름은 전 세계적으로 고유해야 합니다
- 소문자, 숫자, 하이픈(-)만 사용 가능
- IP 주소 형식(192.168.1.1) 사용 불가
- 이름은 변경 불가능하므로 신중하게 선택하세요
</Callout>

<DevTip title="리전 선택 팁">
데이터 레이턴시를 최소화하려면 사용자와 가까운 리전을 선택하세요. 서울 리전(ap-northeast-2)은 한국 사용자에게 가장 빠른 성능을 제공합니다.
</DevTip>

</Step>

---

<Step number={3} title="파일 업로드">

생성한 버킷에 파일을 업로드합니다.

1. 버킷 목록에서 방금 생성한 버킷 클릭
2. **"업로드"** 버튼 클릭
3. **"파일 추가"** 또는 **"폴더 추가"** 클릭
4. 업로드할 파일 선택 (예: 이미지, PDF, HTML 파일 등)
5. (선택사항) **스토리지 클래스** 선택
   - **S3 Standard**: 자주 액세스하는 데이터 (기본값)
   - **S3 Standard-IA**: 자주 액세스하지 않는 데이터 (비용 절감)
   - **S3 Glacier**: 아카이브 데이터 (최저 비용)
6. 페이지 하단의 **"업로드"** 클릭

<Screenshot
  src="https://res.cloudinary.com/demo/image/upload/v1/guides/aws-s3-bucket-setup/step3-upload-file-ko.png"
  alt="S3 파일 업로드 화면"
  caption="파일을 선택하고 스토리지 클래스를 지정합니다"
/>

<Checkpoint>
파일이 정상적으로 업로드되었나요? 버킷의 객체 목록에서 업로드한 파일을 확인할 수 있어야 합니다.
</Checkpoint>

<DevTip title="대용량 파일 업로드">
100MB 이상의 파일은 AWS CLI 또는 SDK를 사용하는 것이 더 효율적입니다. 멀티파트 업로드를 통해 대용량 파일을 안정적으로 업로드할 수 있습니다.

```bash
# AWS CLI로 파일 업로드
aws s3 cp large-file.zip s3://my-app-storage-2026/

# 폴더 전체 동기화
aws s3 sync ./local-folder s3://my-app-storage-2026/backup/
```
</DevTip>

</Step>

---

<Step number={4} title="버킷 권한 및 퍼블릭 액세스 설정">

파일에 대한 액세스 권한을 설정합니다.

### 퍼블릭 액세스 차단 해제 (필요한 경우만)

1. 버킷 페이지에서 **"권한"** 탭 클릭
2. **"퍼블릭 액세스 차단"** 섹션에서 **"편집"** 클릭
3. 필요에 따라 차단 해제 (정적 웹사이트 호스팅 시 필요)
4. 확인 텍스트 입력 후 **"확인"** 클릭

### 개별 파일을 퍼블릭으로 설정

1. 버킷의 **"객체"** 탭에서 파일 선택
2. **"작업"** → **"ACL을 사용하여 퍼블릭으로 설정"** 클릭

<Screenshot
  src="https://res.cloudinary.com/demo/image/upload/v1/guides/aws-s3-bucket-setup/step4-permissions-ko.png"
  alt="S3 버킷 권한 설정"
  caption="퍼블릭 액세스 차단 설정을 관리합니다"
/>

<Callout type="danger" title="보안 주의사항">
퍼블릭 액세스는 누구나 파일에 접근할 수 있게 합니다. 민감한 데이터가 포함된 버킷은 절대 퍼블릭으로 설정하지 마세요. 필요한 경우 버킷 정책이나 사전 서명된 URL을 사용하세요.
</Callout>

<DevTip title="버킷 정책으로 세밀한 권한 제어">
특정 조건에서만 액세스를 허용하려면 버킷 정책을 사용하세요.

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "PublicReadGetObject",
      "Effect": "Allow",
      "Principal": "*",
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::my-app-storage-2026/public/*"
    }
  ]
}
```

이 정책은 `public/` 폴더의 파일만 퍼블릭 읽기를 허용합니다.
</DevTip>

</Step>

---

<Step number={5} title="정적 웹사이트 호스팅 활성화">

S3를 사용해 정적 웹사이트를 호스팅합니다.

1. 버킷 페이지에서 **"속성"** 탭 클릭
2. 페이지 하단의 **"정적 웹 사이트 호스팅"** 섹션 찾기
3. **"편집"** 클릭
4. **"활성화"** 선택
5. **호스팅 유형**: **"정적 웹 사이트 호스팅"** 선택
6. **인덱스 문서** 입력: `index.html`
7. (선택) **오류 문서** 입력: `error.html`
8. **"변경 사항 저장"** 클릭
9. 생성된 **버킷 웹 사이트 엔드포인트** URL 복사

<Screenshot
  src="https://res.cloudinary.com/demo/image/upload/v1/guides/aws-s3-bucket-setup/step5-static-website-ko.png"
  alt="S3 정적 웹사이트 호스팅 설정"
  caption="정적 웹사이트 호스팅을 활성화합니다"
/>

<Checkpoint>
웹사이트 엔드포인트 URL에 접속했을 때 index.html 파일이 표시되나요?
</Checkpoint>

<DevTip title="간단한 index.html 예제">
테스트용 index.html 파일:

```html
<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>내 S3 웹사이트</title>
</head>
<body>
  <h1>AWS S3 정적 웹사이트 호스팅 성공!</h1>
  <p>이 페이지는 S3 버킷에서 제공됩니다.</p>
</body>
</html>
```

이 파일을 버킷에 업로드하고 웹사이트 엔드포인트로 접속해보세요.
</DevTip>

</Step>

---

<Step number={6} title="수명 주기 규칙 설정 (비용 최적화)">

오래된 파일을 자동으로 삭제하거나 저렴한 스토리지 클래스로 이동시킵니다.

1. 버킷 페이지에서 **"관리"** 탭 클릭
2. **"수명 주기 규칙"** 섹션에서 **"수명 주기 규칙 생성"** 클릭
3. **수명 주기 규칙 이름** 입력 (예: `auto-archive-old-files`)
4. **규칙 범위** 선택:
   - 전체 버킷 또는 특정 접두사/태그
5. **수명 주기 규칙 작업** 선택:
   - **"객체의 현재 버전 간 전환"**: 30일 후 Standard-IA로 이동
   - **"객체의 현재 버전 만료"**: 90일 후 삭제
6. **"규칙 생성"** 클릭

<Screenshot
  src="https://res.cloudinary.com/demo/image/upload/v1/guides/aws-s3-bucket-setup/step6-lifecycle-ko.png"
  alt="S3 수명 주기 규칙 설정"
  caption="수명 주기 규칙으로 스토리지 비용을 최적화합니다"
/>

<Callout type="tip" title="비용 최적화 전략">
- 자주 액세스하지 않는 로그 파일: 30일 후 Standard-IA로 이동
- 아카이브용 백업: 90일 후 Glacier로 이동
- 임시 파일: 7일 후 자동 삭제
</Callout>

<DevTip title="S3 Intelligent-Tiering">
액세스 패턴을 예측하기 어렵다면 **S3 Intelligent-Tiering**을 사용하세요. 자동으로 객체를 적절한 스토리지 클래스로 이동시켜 비용을 최적화합니다.

```bash
# CLI로 Intelligent-Tiering 설정
aws s3api put-bucket-intelligent-tiering-configuration \
  --bucket my-app-storage-2026 \
  --id EntireBucket \
  --intelligent-tiering-configuration file://tiering.json
```
</DevTip>

</Step>

---

## 다음 단계

S3 버킷 설정을 완료했습니다! 이제 다음 작업을 시도해보세요:

- **Lambda와 연동**: S3 이벤트를 트리거로 Lambda 함수 실행
- **CloudFront 연동**: CDN을 통해 전 세계적으로 빠른 콘텐츠 제공
- **버전 관리 활성화**: 파일 변경 이력 추적 및 복원
- **암호화 설정**: 서버 측 암호화(SSE-S3, SSE-KMS)로 데이터 보호
- **S3 SDK 사용**: Python boto3 또는 Node.js AWS SDK로 프로그래매틱 액세스

<CopyBlock language="python" title="Python boto3로 S3 사용">
```python
import boto3

# S3 클라이언트 생성
s3 = boto3.client('s3')

# 파일 업로드
s3.upload_file('local-file.txt', 'my-app-storage-2026', 'uploaded-file.txt')

# 파일 다운로드
s3.download_file('my-app-storage-2026', 'uploaded-file.txt', 'downloaded-file.txt')

# 파일 목록 조회
response = s3.list_objects_v2(Bucket='my-app-storage-2026')
for obj in response.get('Contents', []):
    print(obj['Key'])
```
</CopyBlock>

<CopyBlock language="javascript" title="Node.js AWS SDK로 S3 사용">
```javascript
const { S3Client, PutObjectCommand, GetObjectCommand } = require('@aws-sdk/client-s3');
const fs = require('fs');

const s3Client = new S3Client({ region: 'ap-northeast-2' });

// 파일 업로드
async function uploadFile() {
  const fileContent = fs.readFileSync('local-file.txt');

  const command = new PutObjectCommand({
    Bucket: 'my-app-storage-2026',
    Key: 'uploaded-file.txt',
    Body: fileContent
  });

  await s3Client.send(command);
  console.log('파일 업로드 완료');
}

uploadFile();
```
</CopyBlock>

<Callout type="info" title="관련 가이드">
- [AWS Lambda 함수 생성하기](/guides/aws-lambda-setup) - S3 이벤트 트리거 설정
- [AWS DynamoDB 설정하기](/guides/aws-dynamodb-setup) - S3와 함께 사용하는 데이터베이스
</Callout>
